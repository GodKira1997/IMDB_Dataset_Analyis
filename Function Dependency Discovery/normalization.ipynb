{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import configparser as configparser\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching new_relation_movie table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtion: To parse INI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ini(section: str) -> dict:\n",
    "    \"\"\"\n",
    "    This function parses ini file for configuration details\n",
    "    :param section: section to read from ini\n",
    "    :return: Dictionary of config details\n",
    "    \"\"\"\n",
    "    config = dict()\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read(\"imdb_database.ini\")\n",
    "    if parser.has_section(section):\n",
    "        config_items = parser.items(section)\n",
    "        for item in config_items:\n",
    "            config[item[0]] = item[1]\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = parse_ini(\"postgresql\")\n",
    "db_config\n",
    "table_name = \"new_relation_movie\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: To connect to IMDB databae and run select query to fetch new_relation_movie table into new_relation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_47676\\412817476.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  new_relation_df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query results loaded to Dataframe\n"
     ]
    }
   ],
   "source": [
    "with psycopg2.connect(**db_config) as conn:\n",
    "    try:\n",
    "        query = \"SELECT * FROM \" + table_name\n",
    "        new_relation_df = pd.read_sql_query(query, conn)\n",
    "        print(\"The query results loaded to Dataframe\")\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"SQL Exception:\" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movieid</th>\n",
       "      <th>type</th>\n",
       "      <th>startyear</th>\n",
       "      <th>runtime</th>\n",
       "      <th>avgrating</th>\n",
       "      <th>genreid</th>\n",
       "      <th>genre</th>\n",
       "      <th>memberid</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>movie</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>179163</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>movie</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6</td>\n",
       "      <td>Sport</td>\n",
       "      <td>179163</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>movie</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>News</td>\n",
       "      <td>179163</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>movie</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>280615</td>\n",
       "      <td>1863.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>movie</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6</td>\n",
       "      <td>Sport</td>\n",
       "      <td>280615</td>\n",
       "      <td>1863.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839663</th>\n",
       "      <td>1839664</td>\n",
       "      <td>26658277</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>14538771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839664</th>\n",
       "      <td>1839665</td>\n",
       "      <td>26658688</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>1715086</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839665</th>\n",
       "      <td>1839666</td>\n",
       "      <td>26658688</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>1760063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839666</th>\n",
       "      <td>1839667</td>\n",
       "      <td>26658688</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>8386585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839667</th>\n",
       "      <td>1839668</td>\n",
       "      <td>26658688</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>14539144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1839668 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   movieid      type  startyear  runtime  avgrating  genreid  \\\n",
       "0              1       147     movie     1897.0      100        5.2        1   \n",
       "1              2       147     movie     1897.0      100        5.2        6   \n",
       "2              3       147     movie     1897.0      100        5.2        7   \n",
       "3              4       147     movie     1897.0      100        5.2        1   \n",
       "4              5       147     movie     1897.0      100        5.2        6   \n",
       "...          ...       ...       ...        ...      ...        ...      ...   \n",
       "1839663  1839664  26658277  tvSeries     2009.0      120        NaN       25   \n",
       "1839664  1839665  26658688  tvSeries     2007.0      240        NaN       25   \n",
       "1839665  1839666  26658688  tvSeries     2007.0      240        NaN       25   \n",
       "1839666  1839667  26658688  tvSeries     2007.0      240        NaN       25   \n",
       "1839667  1839668  26658688  tvSeries     2007.0      240        NaN       25   \n",
       "\n",
       "               genre  memberid  birthyear  character  \n",
       "0        Documentary    179163     1866.0         52  \n",
       "1              Sport    179163     1866.0         52  \n",
       "2               News    179163     1866.0         52  \n",
       "3        Documentary    280615     1863.0         52  \n",
       "4              Sport    280615     1863.0         52  \n",
       "...              ...       ...        ...        ...  \n",
       "1839663    Talk-Show  14538771        NaN         55  \n",
       "1839664    Talk-Show   1715086     1972.0         55  \n",
       "1839665    Talk-Show   1760063        NaN         55  \n",
       "1839666    Talk-Show   8386585        NaN         55  \n",
       "1839667    Talk-Show  14539144        NaN         55  \n",
       "\n",
       "[1839668 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_relation_df = new_relation_df.drop('id', axis=1)\n",
    "new_relation_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes in new_relation_movie table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'movieid',\n",
       " 'type',\n",
       " 'startyear',\n",
       " 'runtime',\n",
       " 'avgrating',\n",
       " 'genreid',\n",
       " 'genre',\n",
       " 'memberid',\n",
       " 'birthyear',\n",
       " 'character']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = list(new_relation_df.columns)\n",
    "attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive approach to find FDs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations of all atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "dependencies = []\n",
    "powerset_attributes = list(chain.from_iterable(combinations(attributes, a) for a in range(2, len(attributes)+1)))\n",
    "powerset_attributes = [list(a) for a in powerset_attributes]\n",
    "powerset_attributes = [[a] for a in attributes] + powerset_attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: To check Dependency using partition refinement\n",
    "It checks the if the count of equivalence classes for set LHS and count of equivalence classes for set (LHS v {RHS}) is same\n",
    "(Simplified partition refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dependency(dataframe, lhs, rhs) -> bool:\n",
    "    count1 = dataframe[list(lhs)].drop_duplicates().shape[0]\n",
    "    lhs_rhs = list(lhs) + [rhs]\n",
    "    count2 = dataframe[list(lhs_rhs)].drop_duplicates().shape[0]\n",
    "    if count1 != count2:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute force checking all the possibilities\n",
    "Restricted to first 121 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lhs in powerset_attributes[:10]:\n",
    "    for rhs in attributes:\n",
    "        if rhs not in lhs:\n",
    "            if check_dependency(new_relation_df, lhs, rhs):\n",
    "                dependencies.append([tuple(lhs), rhs])\n",
    "len(dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning approach to find FDs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(): {'avgrating',\n",
       "  'birthyear',\n",
       "  'character',\n",
       "  'genre',\n",
       "  'genreid',\n",
       "  'id',\n",
       "  'memberid',\n",
       "  'movieid',\n",
       "  'runtime',\n",
       "  'startyear',\n",
       "  'type'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependencies = []\n",
    "candidate_plus_RHS = dict()  # To hold RHS candidates for a given set X\n",
    "previous_level_alphas = [tuple([])]  # level 0\n",
    "candidate_plus_RHS[tuple([])] = set(attributes)  # for level 0\n",
    "candidate_plus_RHS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: To calculate RHS Candidates for a given set X subset of Attributes R of relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_plus_RHS(alpha, previous_level_alphas):\n",
    "    # print(set(alpha))\n",
    "    value = set(attributes)\n",
    "    # print(previous_level_alphas)\n",
    "    for previous_alpha in previous_level_alphas:\n",
    "        # print(set(previous_alpha))\n",
    "        if set(previous_alpha).issubset(set(alpha)):\n",
    "            value = value.intersection(candidate_plus_RHS[tuple(sorted(previous_alpha))])\n",
    "    return value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if set X is a superkey for the new_relation_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_superkey(alpha):\n",
    "    count = new_relation_df[list(alpha)].drop_duplicates().shape[0]\n",
    "    if count == new_relation_df.shape[0]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Algorithm to get functional dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id',), ('movieid',), ('type',), ('startyear',), ('runtime',), ('avgrating',), ('genreid',), ('genre',), ('memberid',), ('birthyear',), ('character',)]\n",
      "[('movieid',), ('type',), ('startyear',), ('runtime',), ('avgrating',), ('genreid',), ('genre',), ('memberid',), ('birthyear',), ('character',)]\n",
      "[('id', 'movieid'), ('id', 'type'), ('id', 'startyear'), ('id', 'runtime'), ('id', 'avgrating'), ('id', 'genreid'), ('id', 'genre'), ('id', 'memberid'), ('id', 'birthyear'), ('id', 'character'), ('movieid', 'type'), ('movieid', 'startyear'), ('movieid', 'runtime'), ('movieid', 'avgrating'), ('movieid', 'genreid'), ('movieid', 'genre'), ('movieid', 'memberid'), ('movieid', 'birthyear'), ('movieid', 'character'), ('type', 'startyear'), ('type', 'runtime'), ('type', 'avgrating'), ('type', 'genreid'), ('type', 'genre'), ('type', 'memberid'), ('type', 'birthyear'), ('type', 'character'), ('startyear', 'runtime'), ('startyear', 'avgrating'), ('startyear', 'genreid'), ('startyear', 'genre'), ('startyear', 'memberid'), ('startyear', 'birthyear'), ('startyear', 'character'), ('runtime', 'avgrating'), ('runtime', 'genreid'), ('runtime', 'genre'), ('runtime', 'memberid'), ('runtime', 'birthyear'), ('runtime', 'character'), ('avgrating', 'genreid'), ('avgrating', 'genre'), ('avgrating', 'memberid'), ('avgrating', 'birthyear'), ('avgrating', 'character'), ('genreid', 'genre'), ('genreid', 'memberid'), ('genreid', 'birthyear'), ('genreid', 'character'), ('genre', 'memberid'), ('genre', 'birthyear'), ('genre', 'character'), ('memberid', 'birthyear'), ('memberid', 'character'), ('birthyear', 'character')]\n"
     ]
    }
   ],
   "source": [
    "current_level_alphas = list(combinations(attributes, 1))  # All Alpha's at level '1' in lattice\n",
    "for level in range(1, 4):\n",
    "    print(current_level_alphas)\n",
    "    # Initializing Candidate RHS for all Alpha's\n",
    "    for alpha in current_level_alphas:\n",
    "        alpha = tuple(sorted(alpha))\n",
    "        candidate_plus_RHS[alpha] = get_candidate_plus_RHS(alpha, previous_level_alphas)\n",
    "    # Dependency checking\n",
    "    for alpha in current_level_alphas:\n",
    "        alpha = tuple(sorted(alpha))\n",
    "        # Candidate RHS should be a subset(in domain) of Alpha\n",
    "        possible_rhs = set(alpha).intersection(candidate_plus_RHS[alpha])\n",
    "        for rhs in list(possible_rhs):\n",
    "            lhs = list(set(alpha).difference({rhs}))  # Alpha\\{RHS} -> RHS\n",
    "            if lhs == None or len(lhs) <= 0:\n",
    "                continue\n",
    "            if check_dependency(new_relation_df, lhs, rhs):\n",
    "                dependencies.append([tuple(lhs), rhs])\n",
    "                # RHS Candidate Pruning\n",
    "                # Remove rhs\n",
    "                candidate_plus_RHS[alpha].remove(rhs)\n",
    "                # Remove all attributes that doesn't belong to Alpha\n",
    "                R_alpha = set(attributes).difference(set(alpha))\n",
    "                candidate_plus_RHS[alpha] = candidate_plus_RHS[alpha].difference(R_alpha)\n",
    "    # Pruning\n",
    "    prune_alphas = []\n",
    "    for alpha in current_level_alphas:\n",
    "        alpha = tuple(sorted(alpha))\n",
    "        if not bool(candidate_plus_RHS[alpha]):  # if Candidate RHS is empty\n",
    "            prune_alphas.append(set(alpha))\n",
    "        if is_superkey(alpha): # Add all depedencies possible as it is superkey\n",
    "            for A in list(candidate_plus_RHS[alpha].difference(set(alpha))):\n",
    "                reduction = set(attributes)\n",
    "                for B in list(alpha):\n",
    "                    x = [i for i in set(alpha).union({A}).difference({B})]\n",
    "                    x = sorted(x)\n",
    "                    # print(tuple(x))\n",
    "                    reduction.intersection(candidate_plus_RHS[tuple(x)])\n",
    "                if A in reduction:\n",
    "                    dependencies.append([alpha, A])\n",
    "            prune_alphas.append(set(alpha))\n",
    "    # Generating Alpha's for next level\n",
    "    previous_level_alphas = current_level_alphas\n",
    "    current_level_alphas = list(combinations(attributes, level))\n",
    "    for alpha in current_level_alphas:\n",
    "        for pruned in prune_alphas:\n",
    "            if set(alpha).issuperset(pruned):\n",
    "                current_level_alphas.remove(alpha)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_dependencies = set()\n",
    "for x in dependencies:\n",
    "    minimal_dependencies.add(tuple(x))\n",
    "minimal_dependencies\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
